# Hi, I'm Riteng (Gavin) Zhang! üëã


## üåû About Me
An undergraduate student from Boston College who loves to study deep neural network interpretability. I am majoring in Math and CS, with a philosophy minor.

- üî≠ Currently working on my thesis and independent research (advised by [Professor Emily Prud'hommeaux](https://www.bc.edu/bc-web/schools/mcas/departments/computer-science/people/faculty-directory/emily-prudhommeaux.html) and [Professor Sergio Alvarez](https://www.bc.edu/bc-web/schools/mcas/departments/computer-science/people/faculty-directory/sergio-alvarez.html)), **Interpretability of Neural Language Model: A Survey** and **Interpretability of Inception and its Variants**.

- üîà Research Assistant works for [Professor Emily Prud'hommeaux](https://www.bc.edu/bc-web/schools/mcas/departments/computer-science/people/faculty-directory/emily-prudhommeaux.html) on topics including ASR for under-resourced language, Language Models Evaluation for Neuroatypical Language, etc.

- üåª Co-founder and machine learning engineer of [Blossoms ai](https://blossoms.ai/about). 

- üì´ Contact Information: **zhangcoj@bc.edu**

- üìÑ Here's my [cv](https://drive.google.com/file/d/1ifqGQyxjWXerkbqMenZ2lG_rHPg0oIrr/view?usp=drive_link).

- ‚ö° Fun fact: I love history and philosophy, and regularly write about those on [social media](https://mp.weixin.qq.com/s?__biz=MzUxMzA5NTYwOA==&mid=2247483679&idx=1&sn=ce7cbf5a52b5e0b824578bdd6b1d764b&chksm=f95b23c8ce2caadeeb78f56216e3dcd88924e9793e035447cca656f0c9d9f2c163dd4e93e39d#rd) (modern Chinese history, Epistemology, and Existentialism in particular).


## ‚úèÔ∏è Research Interest

- Exploring the potential specialties in unique graph designs in deep learning models on certain tasks.

- Systematic Neural NLP interpretability

- Meta-learning theory and its applications in deep learning

- Emergent ability in LLM interpretation and prediction

## üìñ Research

- **Interpretability of Large Language Models and Their Emergent Abilities** (advised by [Professor Emily Prud'hommeaux](https://www.bc.edu/bc-web/schools/mcas/departments/computer-science/people/faculty-directory/emily-prudhommeaux.html))

The interpretability of the black box model itself presents an intriguing yet complex academic question. As Large Language Models (LLMs) have gained increasing popularity in recent years, it becomes imperative for humans to make every effort to comprehend these models. The divergent motivations for addressing this challenge, coupled with the inherent difficulty it poses, contribute to the somewhat chaotic nature of the field of interpretability. Consequently, a comprehensive review paper that systematically organizes the methods, issues, and advancements in this domain is essential. This paper particularly focuses on the intricate relationship between LLM behavior and methods for interpreting LLMs. Drawing inspiration from Table I in the paper titled "[1][Post-hoc Interpretability for Neural NLP: A Survey](https://arxiv.org/abs/2108.04840)", the proposed review paper categorizes the interpretability methods into three dimensions: what aspect of the model is being interpreted, the source of information used for interpretation, and the nature of the information presented to individuals. Moreover, a fourth dimension is considered, accounting for the specifics of the information presentation.
Additionally, the emergent abilities of LLMs also necessitate interpretability. However, only a limited number of traditional methods can be effectively applied in this context. This paper will also delve into the constraints and potentialities of the commonly used interpretability methods when the objective is to comprehend emergent abilities.

- **Interpretability of Inception and its Variants** (advised by [Professor Sergio Alvarez](https://www.bc.edu/bc-web/schools/mcas/departments/computer-science/people/faculty-directory/sergio-alvarez.html))

It is intuitive to infer from the design of the Inception model that the foundational CNN blocks are ideally adaptive, thereby providing the model with a greater potential for learning various tasks of different kinds more efficiently. How do the weights of different kernel sizes in its architecture change when the model is trained on different tasks at various stages of training? Can we establish the adaptiveness of the CNN blocks in models like Inception?

- **CS placement test automation framework** (preprint, with a different title)

Different types of models, including LLMs, are utilized to create an automated process for conducting a Computer Science (CS) placement test in a step-by-step manner. The framework's limitations and potential are discussed.

- **Evaluation of LLM Zero to Few-Shot Ability when Expecting Formatted Output** (advised by [Professor Emily Prud'hommeaux](https://www.bc.edu/bc-web/schools/mcas/departments/computer-science/people/faculty-directory/emily-prudhommeaux.html))

It is simple to use LLM like GPT chat creation as a chatbot, but what if we want LLMs with chat creation functions to do a traditional task on a huge dataset? The high-quality content in LLMs' output is assured for such traditional tasks even when using zero-shot, but without using fine-tuning or few-shot, the output is not formatted in any expected way. How to make LLMs output in an expected way? Do we give instructions? How many examples for Few-Shot? Is fine-tuning still necessary even when the format is complicated?

- **Large ASR Model Evaluation for Under-resourced Language** (PI: [Professor Emily Prud'hommeaux](https://www.bc.edu/bc-web/schools/mcas/departments/computer-science/people/faculty-directory/emily-prudhommeaux.html)) 

- **Language Models Evaluation for Neuroatypical Language** (PI: [Professor Emily Prud'hommeaux](https://www.bc.edu/bc-web/schools/mcas/departments/computer-science/people/faculty-directory/emily-prudhommeaux.html))


## üè¢ Startup-[Blossoms ai](https://blossoms.ai/about)
At BlossomsAI, we are on a mission to transform education by leveraging the power of artificial intelligence. We firmly believe that a personalized, individualized, and customized approach to education can unlock the full potential of every child. Our goal is to equip teachers with the tools and resources necessary to save time, increase efficiency, and focus on nurturing each student's unique abilities and interests. 

As co-founder and machine learning engineer in the company, I am responsible for everything related to AI or ML in BlossomsAIÔºå including necessary research and back-end coding using Pytorch customized models, hugging face models, LLMs APIs for many different usages expected in our product.

## Reference
[1] Madsen, Andreas, Siva Reddy, and Sarath Chandar. "[Post-hoc Interpretability for Neural NLP: A Survey](https://arxiv.org/abs/2108.04840)." ACM Computing Surveys 55, no. 8 (2022): 1-42.
